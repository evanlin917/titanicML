{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanicML-LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg3YGK/UBazYJLFToMQ0eX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evanlin917/titanicML-LogisticRegression/blob/main/titanicML_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2TZ2xS_S-bz",
        "outputId": "77061f35-5452-471c-954c-8eb599479b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PSsZlo9NPWEc",
        "outputId": "2a46c710-a5f7-4626-bcaa-49fd8a56966e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e6290d8-3e81-4906-a806-3ac5aeb09f89\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e6290d8-3e81-4906-a806-3ac5aeb09f89\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving titanic_train.csv to titanic_train (6).csv\n",
            "<bound method NDFrame.head of      pclass     sex   age  sibsp  parch     fare  survived\n",
            "1         3    male  38.0      0      0   8.6625         0\n",
            "2         3  female  30.0      1      1  24.1500         0\n",
            "3         2  female  54.0      1      3  23.0000         1\n",
            "4         2    male  40.0      0      0  13.0000         0\n",
            "5         3    male  28.0      0      0  22.5250         0\n",
            "..      ...     ...   ...    ...    ...      ...       ...\n",
            "845       1    male  55.0      0      0  50.0000         0\n",
            "846       1    male  58.0      0      0  29.7000         0\n",
            "847       2  female  24.0      1      0  26.0000         1\n",
            "848       3  female   3.0      1      1  13.7750         0\n",
            "849       2    male  52.0      0      0  13.0000         0\n",
            "\n",
            "[675 rows x 7 columns]>\n",
            "<bound method NDFrame.head of      pclass     sex   age  sibsp  parch     fare  survived   male\n",
            "1         3    male  38.0      0      0   8.6625         0   True\n",
            "2         3  female  30.0      1      1  24.1500         0  False\n",
            "3         2  female  54.0      1      3  23.0000         1  False\n",
            "4         2    male  40.0      0      0  13.0000         0   True\n",
            "5         3    male  28.0      0      0  22.5250         0   True\n",
            "..      ...     ...   ...    ...    ...      ...       ...    ...\n",
            "845       1    male  55.0      0      0  50.0000         0   True\n",
            "846       1    male  58.0      0      0  29.7000         0   True\n",
            "847       2  female  24.0      1      0  26.0000         1  False\n",
            "848       3  female   3.0      1      1  13.7750         0  False\n",
            "849       2    male  52.0      0      0  13.0000         0   True\n",
            "\n",
            "[675 rows x 8 columns]>\n",
            "[[3 True 38.0 0 0 8.6625]\n",
            " [3 False 30.0 1 1 24.15]\n",
            " [2 False 54.0 1 3 23.0]\n",
            " ...\n",
            " [2 False 24.0 1 0 26.0]\n",
            " [3 False 3.0 1 1 13.775]\n",
            " [2 True 52.0 0 0 13.0]]\n",
            "[0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1\n",
            " 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0\n",
            " 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1\n",
            " 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1\n",
            " 0 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1\n",
            " 1 1 0 1 0 0 1 0 0]\n",
            "[[-1.12544016e+00 -2.26431173e+00 -4.06639589e-02 -4.07550847e-01\n",
            "   1.36553852e-01  1.65996008e-03]] [4.65073195]\n",
            "[0]\n",
            "[0 0 1 0 0]\n",
            "[0 0 1 0 0]\n",
            "529\n",
            "0.7837037037037037\n",
            "0.7837037037037037\n",
            "accuracy:  0.7837037037037037\n",
            "precision:  0.7439024390243902\n",
            "recall:  0.6879699248120301\n",
            "f1 score:  0.71484375\n",
            "[[346  63]\n",
            " [ 83 183]]\n",
            "whole dataset:  (675, 6) (675,)\n",
            "training set:  (540, 6) (540,)\n",
            "test set:  (135, 6) (135,)\n",
            "0.6962962962962963\n",
            "accuracy:  0.6962962962962963\n",
            "precision:  0.6595744680851063\n",
            "recall:  0.5535714285714286\n",
            "f1 score:  0.6019417475728156\n",
            "0.5535714285714286\n",
            "predict proba: \n",
            "[[0.89831053 0.10168947]\n",
            " [0.3035991  0.6964009 ]\n",
            " [0.1447122  0.8552878 ]\n",
            " [0.37329573 0.62670427]\n",
            " [0.93110835 0.06889165]\n",
            " [0.96487971 0.03512029]\n",
            " [0.83310498 0.16689502]\n",
            " [0.64390026 0.35609974]\n",
            " [0.81155327 0.18844673]\n",
            " [0.06457136 0.93542864]\n",
            " [0.89410673 0.10589327]\n",
            " [0.96296934 0.03703066]\n",
            " [0.89393181 0.10606819]\n",
            " [0.31982741 0.68017259]\n",
            " [0.71858477 0.28141523]\n",
            " [0.58930607 0.41069393]\n",
            " [0.33857092 0.66142908]\n",
            " [0.18646645 0.81353355]\n",
            " [0.54584429 0.45415571]\n",
            " [0.91446563 0.08553437]\n",
            " [0.93969266 0.06030734]\n",
            " [0.27625521 0.72374479]\n",
            " [0.4837056  0.5162944 ]\n",
            " [0.5987745  0.4012255 ]\n",
            " [0.13560611 0.86439389]\n",
            " [0.17602208 0.82397792]\n",
            " [0.19923869 0.80076131]\n",
            " [0.42962901 0.57037099]\n",
            " [0.07103171 0.92896829]\n",
            " [0.6977654  0.3022346 ]\n",
            " [0.17583422 0.82416578]\n",
            " [0.25774957 0.74225043]\n",
            " [0.93113283 0.06886717]\n",
            " [0.45010433 0.54989567]\n",
            " [0.92453813 0.07546187]\n",
            " [0.50792159 0.49207841]\n",
            " [0.9398112  0.0601888 ]\n",
            " [0.58318072 0.41681928]\n",
            " [0.94960356 0.05039644]\n",
            " [0.91058752 0.08941248]\n",
            " [0.44136121 0.55863879]\n",
            " [0.71908347 0.28091653]\n",
            " [0.08308266 0.91691734]\n",
            " [0.61902858 0.38097142]\n",
            " [0.8190528  0.1809472 ]\n",
            " [0.13969526 0.86030474]\n",
            " [0.74418019 0.25581981]\n",
            " [0.39908425 0.60091575]\n",
            " [0.90257174 0.09742826]\n",
            " [0.19116019 0.80883981]\n",
            " [0.0533457  0.9466543 ]\n",
            " [0.76244272 0.23755728]\n",
            " [0.77942345 0.22057655]\n",
            " [0.89221516 0.10778484]\n",
            " [0.45761278 0.54238722]\n",
            " [0.59648551 0.40351449]\n",
            " [0.70475942 0.29524058]\n",
            " [0.41817107 0.58182893]\n",
            " [0.77118552 0.22881448]\n",
            " [0.05753169 0.94246831]\n",
            " [0.83836042 0.16163958]\n",
            " [0.55754042 0.44245958]\n",
            " [0.70764457 0.29235543]\n",
            " [0.64712068 0.35287932]\n",
            " [0.51732198 0.48267802]\n",
            " [0.81027348 0.18972652]\n",
            " [0.1357968  0.8642032 ]\n",
            " [0.80149085 0.19850915]\n",
            " [0.2574882  0.7425118 ]\n",
            " [0.76385171 0.23614829]\n",
            " [0.47498931 0.52501069]\n",
            " [0.85601177 0.14398823]\n",
            " [0.5366948  0.4633052 ]\n",
            " [0.32964314 0.67035686]\n",
            " [0.93769081 0.06230919]\n",
            " [0.71741979 0.28258021]\n",
            " [0.01269225 0.98730775]\n",
            " [0.47043388 0.52956612]\n",
            " [0.86619938 0.13380062]\n",
            " [0.6767263  0.3232737 ]\n",
            " [0.66656009 0.33343991]\n",
            " [0.79120772 0.20879228]\n",
            " [0.92468264 0.07531736]\n",
            " [0.74599028 0.25400972]\n",
            " [0.94351157 0.05648843]\n",
            " [0.22477534 0.77522466]\n",
            " [0.89406473 0.10593527]\n",
            " [0.55394875 0.44605125]\n",
            " [0.05748069 0.94251931]\n",
            " [0.96761931 0.03238069]\n",
            " [0.74636702 0.25363298]\n",
            " [0.5056491  0.4943509 ]\n",
            " [0.08473002 0.91526998]\n",
            " [0.86931793 0.13068207]\n",
            " [0.7864813  0.2135187 ]\n",
            " [0.40304038 0.59695962]\n",
            " [0.87077423 0.12922577]\n",
            " [0.9248355  0.0751645 ]\n",
            " [0.18462998 0.81537002]\n",
            " [0.5456832  0.4543168 ]\n",
            " [0.70795424 0.29204576]\n",
            " [0.95965073 0.04034927]\n",
            " [0.03674667 0.96325333]\n",
            " [0.88233494 0.11766506]\n",
            " [0.85719869 0.14280131]\n",
            " [0.93420261 0.06579739]\n",
            " [0.50445369 0.49554631]\n",
            " [0.87459734 0.12540266]\n",
            " [0.55844183 0.44155817]\n",
            " [0.92151628 0.07848372]\n",
            " [0.92778202 0.07221798]\n",
            " [0.02718402 0.97281598]\n",
            " [0.87964168 0.12035832]\n",
            " [0.32763828 0.67236172]\n",
            " [0.8648532  0.1351468 ]\n",
            " [0.45303656 0.54696344]\n",
            " [0.41745604 0.58254396]\n",
            " [0.0731721  0.9268279 ]\n",
            " [0.86383875 0.13616125]\n",
            " [0.25396263 0.74603737]\n",
            " [0.98242162 0.01757838]\n",
            " [0.87461205 0.12538795]\n",
            " [0.21492161 0.78507839]\n",
            " [0.90676627 0.09323373]\n",
            " [0.85208694 0.14791306]\n",
            " [0.88426206 0.11573794]\n",
            " [0.14964286 0.85035714]\n",
            " [0.54387921 0.45612079]\n",
            " [0.64093076 0.35906924]\n",
            " [0.73685334 0.26314666]\n",
            " [0.95545143 0.04454857]\n",
            " [0.57475292 0.42524708]\n",
            " [0.57066756 0.42933244]\n",
            " [0.84683732 0.15316268]\n",
            " [0.37314135 0.62685865]]\n",
            "precision:  0.75\n",
            "recall:  0.32142857142857145\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7583634719710669\n",
            "[  0   1   2   3   4   6   7   8   9  11  12  13  14  15  16  17  20  22\n",
            "  23  24  25  26  27  28  29  30  31  33  34  35  36  38  39  40  41  42\n",
            "  43  45  46  47  49  50  51  52  53  54  57  58  59  61  62  63  65  66\n",
            "  67  68  71  72  73  74  75  77  78  79  81  82  84  85  87  88  91  92\n",
            "  93  94  96  98  99 100 101 102 103 104 106 107 108 109 111 115 116 117\n",
            " 118 121 122 124 125 126 127 128 130 131 133 135 138 139 142 143 144 145\n",
            " 146 147 148 149 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
            " 165 166 167 168 169 170 171 173 174 175 176 177 179 181 182 183 185 186\n",
            " 188 189 190 191 192 193 194 195 196 197 198 200 201 202 203 205 208 209\n",
            " 210 211 212 213 214 215 216 218 219 220 221 222 223 224 226 227 228 229\n",
            " 230 231 232 233 234 235 236 237 240 242 243 244 245 246 247 248 250 252\n",
            " 253 254 255 256 257 258 260 261 262 263 264 266 267 268 270 271 273 274\n",
            " 276 278 279 280 281 286 287 288 289 291 292 293 294 295 296 298 299 300\n",
            " 301 303 304 306 307 308 309 310 311 312 313 314 315 317 318 319 320 321\n",
            " 322 323 324 325 326 327 328 329 330 331 333 334 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 351 352 355 356 358 359 360 361 362 363\n",
            " 365 366 367 369 370 371 373 374 375 376 377 380 382 383 384 385 386 387\n",
            " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405\n",
            " 406 407 409 411 412 413 414 415 416 417 418 419 420 421 422 423 425 426\n",
            " 427 428 429 431 432 433 434 435 436 437 438 440 441 442 443 444 445 446\n",
            " 449 450 451 452 454 455 456 457 458 459 461 462 463 464 465 466 467 468\n",
            " 469 470 471 472 473 474 475 477 478 479 480 481 482 483 484 485 486 487\n",
            " 488 489 490 491 492 493 494 497 498 500 501 502 503 504 505 506 508 509\n",
            " 511 512 515 516 518 519 520 521 522 523 525 526 527 528 529 530 531 532\n",
            " 533 534 535 536 537 538 539 542 543 544 545 547 548 550 551 552 554 555\n",
            " 556 560 561 562 563 565 569 571 573 574 575 576 577 578 579 580 584 585\n",
            " 586 587 588 589 590 591 592 593 595 596 597 598 599 600 602 603 604 605\n",
            " 606 607 609 610 611 612 613 614 615 618 620 622 624 625 626 627 629 630\n",
            " 631 633 634 635 636 637 638 639 640 641 642 643 644 645 647 648 649 650\n",
            " 651 652 653 654 656 657 658 659 662 664 665 666 667 669 670 671 672 674] [  5  10  18  19  21  32  37  44  48  55  56  60  64  69  70  76  80  83\n",
            "  86  89  90  95  97 105 110 112 113 114 119 120 123 129 132 134 136 137\n",
            " 140 141 150 172 178 180 184 187 199 204 206 207 217 225 238 239 241 249\n",
            " 251 259 265 269 272 275 277 282 283 284 285 290 297 302 305 316 332 335\n",
            " 350 353 354 357 364 368 372 378 379 381 408 410 424 430 439 447 448 453\n",
            " 460 476 495 496 499 507 510 513 514 517 524 540 541 546 549 553 557 558\n",
            " 559 564 566 567 568 570 572 581 582 583 594 601 608 616 617 619 621 623\n",
            " 628 632 646 655 660 661 663 668 673]\n",
            "[  0   1   2   3   4   5   7   8  10  11  12  13  14  16  17  18  19  20\n",
            "  21  22  24  28  29  31  32  33  34  35  36  37  38  39  40  42  43  44\n",
            "  45  46  48  49  50  51  52  53  54  55  56  60  61  62  63  64  65  66\n",
            "  67  69  70  71  72  73  74  76  77  78  79  80  81  83  84  85  86  87\n",
            "  88  89  90  91  92  93  94  95  96  97  98  99 100 102 103 104 105 106\n",
            " 108 109 110 112 113 114 115 116 117 118 119 120 121 123 125 126 129 130\n",
            " 131 132 133 134 135 136 137 139 140 141 142 143 144 146 147 148 150 152\n",
            " 153 154 155 156 158 159 160 162 163 165 166 167 168 169 170 171 172 173\n",
            " 174 175 178 179 180 181 182 183 184 185 186 187 188 189 190 191 193 195\n",
            " 196 198 199 202 203 204 206 207 208 209 210 211 213 214 215 216 217 218\n",
            " 219 220 221 223 224 225 226 227 228 229 230 231 232 234 235 236 238 239\n",
            " 240 241 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259\n",
            " 260 261 262 263 264 265 266 267 268 269 272 273 274 275 277 278 280 281\n",
            " 282 283 284 285 286 288 290 291 292 293 294 295 296 297 298 301 302 304\n",
            " 305 306 307 308 309 310 311 312 313 314 316 317 320 321 323 326 329 330\n",
            " 331 332 333 334 335 336 338 339 340 341 342 344 348 349 350 351 352 353\n",
            " 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 370 372 373\n",
            " 374 375 376 377 378 379 380 381 383 384 385 386 388 389 390 393 395 397\n",
            " 399 400 401 404 406 407 408 409 410 411 412 413 414 418 420 421 422 423\n",
            " 424 425 426 427 429 430 431 434 435 436 437 438 439 441 442 443 444 445\n",
            " 446 447 448 451 452 453 457 458 459 460 461 462 463 464 465 467 468 469\n",
            " 470 471 472 474 475 476 477 478 479 480 481 482 483 484 485 487 488 489\n",
            " 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507\n",
            " 510 511 512 513 514 515 516 517 518 522 523 524 525 526 528 529 531 532\n",
            " 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 549 550 551\n",
            " 553 556 557 558 559 560 561 562 564 565 566 567 568 569 570 571 572 573\n",
            " 574 575 576 577 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
            " 594 595 597 598 599 600 601 602 603 606 608 609 610 614 616 617 618 619\n",
            " 621 623 625 627 628 629 630 632 633 635 636 638 639 641 646 647 649 651\n",
            " 652 653 655 656 659 660 661 662 663 664 665 666 667 668 669 670 672 673] [  6   9  15  23  25  26  27  30  41  47  57  58  59  68  75  82 101 107\n",
            " 111 122 124 127 128 138 145 149 151 157 161 164 176 177 192 194 197 200\n",
            " 201 205 212 222 233 237 242 243 270 271 276 279 287 289 299 300 303 315\n",
            " 318 319 322 324 325 327 328 337 343 345 346 347 369 371 382 387 391 392\n",
            " 394 396 398 402 403 405 415 416 417 419 428 432 433 440 449 450 454 455\n",
            " 456 466 473 486 508 509 519 520 521 527 530 548 552 554 555 563 578 593\n",
            " 596 604 605 607 611 612 613 615 620 622 624 626 631 634 637 640 642 643\n",
            " 644 645 648 650 654 657 658 671 674]\n",
            "[  0   2   3   4   5   6   7   8   9  10  11  12  14  15  17  18  19  20\n",
            "  21  22  23  24  25  26  27  28  30  31  32  33  35  37  39  40  41  43\n",
            "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  59  60  61  63\n",
            "  64  65  66  67  68  69  70  71  73  74  75  76  77  79  80  82  83  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  99 101 102 103 105 107\n",
            " 108 110 111 112 113 114 115 116 117 119 120 121 122 123 124 126 127 128\n",
            " 129 131 132 133 134 136 137 138 139 140 141 144 145 146 147 148 149 150\n",
            " 151 152 156 157 159 161 162 164 165 168 170 172 173 174 175 176 177 178\n",
            " 180 181 182 183 184 185 186 187 188 190 191 192 193 194 195 196 197 198\n",
            " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 215 216 217\n",
            " 220 222 223 225 226 227 229 230 231 232 233 234 235 237 238 239 240 241\n",
            " 242 243 244 246 247 248 249 250 251 252 253 255 256 258 259 260 261 262\n",
            " 263 265 266 267 269 270 271 272 273 275 276 277 278 279 282 283 284 285\n",
            " 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303\n",
            " 304 305 306 307 308 313 315 316 317 318 319 321 322 323 324 325 326 327\n",
            " 328 329 332 333 334 335 336 337 339 340 342 343 344 345 346 347 348 349\n",
            " 350 353 354 355 356 357 359 360 364 365 366 368 369 370 371 372 374 375\n",
            " 376 378 379 380 381 382 383 384 385 387 389 390 391 392 393 394 395 396\n",
            " 397 398 399 402 403 404 405 408 410 412 413 414 415 416 417 418 419 420\n",
            " 423 424 425 426 428 429 430 431 432 433 434 435 436 437 438 439 440 441\n",
            " 442 445 446 447 448 449 450 451 452 453 454 455 456 457 458 460 462 465\n",
            " 466 467 468 469 472 473 474 475 476 479 480 482 483 484 486 487 488 489\n",
            " 491 492 493 494 495 496 497 499 500 501 502 503 504 506 507 508 509 510\n",
            " 511 513 514 515 517 519 520 521 522 524 525 527 530 531 534 535 536 537\n",
            " 538 539 540 541 542 543 546 547 548 549 550 552 553 554 555 557 558 559\n",
            " 560 561 562 563 564 565 566 567 568 569 570 571 572 573 576 577 578 579\n",
            " 581 582 583 585 586 587 588 591 593 594 596 599 601 603 604 605 607 608\n",
            " 611 612 613 615 616 617 618 619 620 621 622 623 624 626 627 628 629 630\n",
            " 631 632 633 634 637 638 639 640 642 643 644 645 646 648 650 651 652 653\n",
            " 654 655 656 657 658 659 660 661 662 663 665 668 669 670 671 672 673 674] [  1  13  16  29  34  36  38  42  51  62  72  78  81  84  98 100 104 106\n",
            " 109 118 125 130 135 142 143 153 154 155 158 160 163 166 167 169 171 179\n",
            " 189 214 218 219 221 224 228 236 245 254 257 264 268 274 280 281 309 310\n",
            " 311 312 314 320 330 331 338 341 351 352 358 361 362 363 367 373 377 386\n",
            " 388 400 401 406 407 409 411 421 422 427 443 444 459 461 463 464 470 471\n",
            " 477 478 481 485 490 498 505 512 516 518 523 526 528 529 532 533 544 545\n",
            " 551 556 574 575 580 584 589 590 592 595 597 598 600 602 606 609 610 614\n",
            " 625 635 636 641 647 649 664 666 667]\n",
            "[  0   1   3   5   6   7   9  10  12  13  14  15  16  18  19  20  21  22\n",
            "  23  24  25  26  27  29  30  31  32  34  36  37  38  39  41  42  44  45\n",
            "  47  48  49  51  55  56  57  58  59  60  62  63  64  66  67  68  69  70\n",
            "  71  72  74  75  76  77  78  80  81  82  83  84  86  89  90  91  92  93\n",
            "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
            " 113 114 116 118 119 120 122 123 124 125 127 128 129 130 131 132 134 135\n",
            " 136 137 138 140 141 142 143 144 145 146 149 150 151 152 153 154 155 157\n",
            " 158 159 160 161 163 164 165 166 167 168 169 170 171 172 173 174 176 177\n",
            " 178 179 180 181 183 184 185 187 189 190 191 192 194 197 198 199 200 201\n",
            " 203 204 205 206 207 210 211 212 213 214 216 217 218 219 221 222 223 224\n",
            " 225 226 227 228 230 231 232 233 236 237 238 239 240 241 242 243 245 248\n",
            " 249 251 252 253 254 256 257 258 259 260 262 264 265 266 268 269 270 271\n",
            " 272 273 274 275 276 277 278 279 280 281 282 283 284 285 287 289 290 291\n",
            " 292 295 296 297 299 300 302 303 305 306 307 309 310 311 312 313 314 315\n",
            " 316 318 319 320 321 322 324 325 327 328 330 331 332 333 334 335 337 338\n",
            " 341 343 345 346 347 350 351 352 353 354 355 357 358 359 361 362 363 364\n",
            " 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 386\n",
            " 387 388 389 391 392 394 396 397 398 399 400 401 402 403 405 406 407 408\n",
            " 409 410 411 414 415 416 417 418 419 421 422 423 424 425 426 427 428 429\n",
            " 430 432 433 434 436 438 439 440 443 444 447 448 449 450 451 452 453 454\n",
            " 455 456 457 458 459 460 461 462 463 464 465 466 468 469 470 471 473 476\n",
            " 477 478 479 480 481 482 483 485 486 487 488 490 495 496 498 499 500 502\n",
            " 505 507 508 509 510 511 512 513 514 516 517 518 519 520 521 523 524 525\n",
            " 526 527 528 529 530 531 532 533 534 535 537 538 539 540 541 542 544 545\n",
            " 546 547 548 549 551 552 553 554 555 556 557 558 559 560 561 562 563 564\n",
            " 566 567 568 569 570 572 573 574 575 576 577 578 580 581 582 583 584 585\n",
            " 589 590 592 593 594 595 596 597 598 599 600 601 602 604 605 606 607 608\n",
            " 609 610 611 612 613 614 615 616 617 619 620 621 622 623 624 625 626 628\n",
            " 631 632 634 635 636 637 640 641 642 643 644 645 646 647 648 649 650 651\n",
            " 652 653 654 655 657 658 660 661 663 664 665 666 667 668 671 672 673 674] [  2   4   8  11  17  28  33  35  40  43  46  50  52  53  54  61  65  73\n",
            "  79  85  87  88  94 115 117 121 126 133 139 147 148 156 162 175 182 186\n",
            " 188 193 195 196 202 208 209 215 220 229 234 235 244 246 247 250 255 261\n",
            " 263 267 286 288 293 294 298 301 304 308 317 323 326 329 336 339 340 342\n",
            " 344 348 349 356 360 365 366 384 385 390 393 395 404 412 413 420 431 435\n",
            " 437 441 442 445 446 467 472 474 475 484 489 491 492 493 494 497 501 503\n",
            " 504 506 515 522 536 543 550 565 571 579 586 587 588 591 603 618 627 629\n",
            " 630 633 638 639 656 659 662 669 670]\n",
            "[  1   2   4   5   6   8   9  10  11  13  15  16  17  18  19  21  23  25\n",
            "  26  27  28  29  30  32  33  34  35  36  37  38  40  41  42  43  44  46\n",
            "  47  48  50  51  52  53  54  55  56  57  58  59  60  61  62  64  65  68\n",
            "  69  70  72  73  75  76  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  94  95  97  98 100 101 104 105 106 107 109 110 111 112 113 114 115\n",
            " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 132 133 134 135\n",
            " 136 137 138 139 140 141 142 143 145 147 148 149 150 151 153 154 155 156\n",
            " 157 158 160 161 162 163 164 166 167 169 171 172 175 176 177 178 179 180\n",
            " 182 184 186 187 188 189 192 193 194 195 196 197 199 200 201 202 204 205\n",
            " 206 207 208 209 212 214 215 217 218 219 220 221 222 224 225 228 229 233\n",
            " 234 235 236 237 238 239 241 242 243 244 245 246 247 249 250 251 254 255\n",
            " 257 259 261 263 264 265 267 268 269 270 271 272 274 275 276 277 279 280\n",
            " 281 282 283 284 285 286 287 288 289 290 293 294 297 298 299 300 301 302\n",
            " 303 304 305 308 309 310 311 312 314 315 316 317 318 319 320 322 323 324\n",
            " 325 326 327 328 329 330 331 332 335 336 337 338 339 340 341 342 343 344\n",
            " 345 346 347 348 349 350 351 352 353 354 356 357 358 360 361 362 363 364\n",
            " 365 366 367 368 369 371 372 373 377 378 379 381 382 384 385 386 387 388\n",
            " 390 391 392 393 394 395 396 398 400 401 402 403 404 405 406 407 408 409\n",
            " 410 411 412 413 415 416 417 419 420 421 422 424 427 428 430 431 432 433\n",
            " 435 437 439 440 441 442 443 444 445 446 447 448 449 450 453 454 455 456\n",
            " 459 460 461 463 464 466 467 470 471 472 473 474 475 476 477 478 481 484\n",
            " 485 486 489 490 491 492 493 494 495 496 497 498 499 501 503 504 505 506\n",
            " 507 508 509 510 512 513 514 515 516 517 518 519 520 521 522 523 524 526\n",
            " 527 528 529 530 532 533 536 540 541 543 544 545 546 548 549 550 551 552\n",
            " 553 554 555 556 557 558 559 563 564 565 566 567 568 570 571 572 574 575\n",
            " 578 579 580 581 582 583 584 586 587 588 589 590 591 592 593 594 595 596\n",
            " 597 598 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615\n",
            " 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633\n",
            " 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 654\n",
            " 655 656 657 658 659 660 661 662 663 664 666 667 668 669 670 671 673 674] [  0   3   7  12  14  20  22  24  31  39  45  49  63  66  67  71  74  77\n",
            "  91  92  93  96  99 102 103 108 116 131 144 146 152 159 165 168 170 173\n",
            " 174 181 183 185 190 191 198 203 210 211 213 216 223 226 227 230 231 232\n",
            " 240 248 252 253 256 258 260 262 266 273 278 291 292 295 296 306 307 313\n",
            " 321 333 334 355 359 370 374 375 376 380 383 389 397 399 414 418 423 425\n",
            " 426 429 434 436 438 451 452 457 458 462 465 468 469 479 480 482 483 487\n",
            " 488 500 502 511 525 531 534 535 537 538 539 542 547 560 561 562 569 573\n",
            " 576 577 585 599 651 652 653 665 672]\n",
            "(array([  1,   2,   4,   5,   8,   9,  11,  13,  15,  16,  17,  18,  19,\n",
            "        20,  21,  22,  23,  24,  25,  26,  27,  29,  30,  32,  34,  36,\n",
            "        37,  40,  41,  42,  43,  46,  47,  49,  52,  53,  54,  55,  56,\n",
            "        57,  58,  59,  60,  61,  62,  63,  64,  66,  68,  69,  70,  71,\n",
            "        72,  73,  74,  75,  76,  78,  82,  83,  84,  85,  86,  87,  88,\n",
            "        89,  91,  92,  93,  94,  95,  96,  97,  99, 101, 102, 103, 106,\n",
            "       107, 108, 109, 110, 111, 112, 113, 115, 116, 118, 119, 120, 121,\n",
            "       123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 138, 139, 140,\n",
            "       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
            "       154, 155, 156, 157, 158, 160, 161, 162, 164, 165, 166, 167, 168,\n",
            "       169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183,\n",
            "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
            "       199, 200, 202, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215,\n",
            "       216, 217, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231,\n",
            "       232, 233, 234, 236, 237, 238, 243, 244, 246, 247, 248, 249, 250,\n",
            "       251, 252, 254, 255, 256, 258, 259, 261, 262, 264, 265, 266, 267,\n",
            "       268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281,\n",
            "       282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
            "       295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 307, 310, 311,\n",
            "       312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 325, 326, 327,\n",
            "       328, 329, 330, 331, 332, 334, 335, 336, 337, 340, 341, 342, 343,\n",
            "       345, 346, 347, 348, 349, 352, 354, 355, 356, 357, 358, 359, 360,\n",
            "       361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375,\n",
            "       376, 377, 378, 379, 380, 382, 383, 384, 385, 387, 388, 389, 390,\n",
            "       391, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
            "       407, 408, 409, 410, 412, 413, 414, 415, 417, 418, 419, 420, 421,\n",
            "       422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 435,\n",
            "       436, 437, 438, 439, 442, 443, 444, 446, 448, 449, 450, 451, 452,\n",
            "       453, 454, 456, 457, 458, 460, 461, 463, 464, 465, 466, 467, 469,\n",
            "       470, 471, 472, 473, 474, 475, 477, 478, 479, 481, 483, 484, 486,\n",
            "       488, 489, 490, 491, 492, 493, 494, 495, 496, 498, 499, 500, 502,\n",
            "       504, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518,\n",
            "       521, 522, 523, 524, 525, 527, 528, 529, 530, 531, 533, 535, 536,\n",
            "       537, 539, 540, 541, 542, 543, 544, 545, 548, 549, 551, 552, 553,\n",
            "       554, 555, 557, 558, 562, 563, 565, 566, 567, 568, 569, 572, 573,\n",
            "       574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 585, 587, 588,\n",
            "       589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
            "       603, 604, 605, 606, 608, 610, 612, 615, 616, 618, 619, 621, 622,\n",
            "       623, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
            "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 648, 649, 650,\n",
            "       651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664,\n",
            "       665, 666, 668, 669, 671, 672, 673]), array([  0,   3,   6,   7,  10,  12,  14,  28,  31,  33,  35,  38,  39,\n",
            "        44,  45,  48,  50,  51,  65,  67,  77,  79,  80,  81,  90,  98,\n",
            "       100, 104, 105, 114, 117, 122, 124, 129, 131, 134, 137, 159, 163,\n",
            "       177, 178, 196, 198, 201, 203, 204, 213, 219, 221, 226, 235, 239,\n",
            "       240, 241, 242, 245, 253, 257, 260, 263, 275, 304, 306, 308, 309,\n",
            "       315, 319, 320, 333, 338, 339, 344, 350, 351, 353, 364, 374, 381,\n",
            "       386, 393, 394, 406, 411, 416, 433, 440, 441, 445, 447, 455, 459,\n",
            "       462, 468, 476, 480, 482, 485, 487, 497, 501, 503, 505, 517, 519,\n",
            "       520, 526, 532, 534, 538, 546, 547, 550, 556, 559, 560, 561, 564,\n",
            "       570, 571, 580, 586, 591, 607, 609, 611, 613, 614, 617, 620, 624,\n",
            "       647, 656, 667, 670, 674]))\n",
            "training set indices:  [  1   2   4   5   8   9  11  13  15  16  17  18  19  20  21  22  23  24\n",
            "  25  26  27  29  30  32  34  36  37  40  41  42  43  46  47  49  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  66  68  69  70  71  72  73\n",
            "  74  75  76  78  82  83  84  85  86  87  88  89  91  92  93  94  95  96\n",
            "  97  99 101 102 103 106 107 108 109 110 111 112 113 115 116 118 119 120\n",
            " 121 123 125 126 127 128 130 132 133 135 136 138 139 140 141 142 143 144\n",
            " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 160 161 162 164\n",
            " 165 166 167 168 169 170 171 172 173 174 175 176 179 180 181 182 183 184\n",
            " 185 186 187 188 189 190 191 192 193 194 195 197 199 200 202 205 206 207\n",
            " 208 209 210 211 212 214 215 216 217 218 220 222 223 224 225 227 228 229\n",
            " 230 231 232 233 234 236 237 238 243 244 246 247 248 249 250 251 252 254\n",
            " 255 256 258 259 261 262 264 265 266 267 268 269 270 271 272 273 274 276\n",
            " 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294\n",
            " 295 296 297 298 299 300 301 302 303 305 307 310 311 312 313 314 316 317\n",
            " 318 321 322 323 324 325 326 327 328 329 330 331 332 334 335 336 337 340\n",
            " 341 342 343 345 346 347 348 349 352 354 355 356 357 358 359 360 361 362\n",
            " 363 365 366 367 368 369 370 371 372 373 375 376 377 378 379 380 382 383\n",
            " 384 385 387 388 389 390 391 392 395 396 397 398 399 400 401 402 403 404\n",
            " 405 407 408 409 410 412 413 414 415 417 418 419 420 421 422 423 424 425\n",
            " 426 427 428 429 430 431 432 434 435 436 437 438 439 442 443 444 446 448\n",
            " 449 450 451 452 453 454 456 457 458 460 461 463 464 465 466 467 469 470\n",
            " 471 472 473 474 475 477 478 479 481 483 484 486 488 489 490 491 492 493\n",
            " 494 495 496 498 499 500 502 504 506 507 508 509 510 511 512 513 514 515\n",
            " 516 518 521 522 523 524 525 527 528 529 530 531 533 535 536 537 539 540\n",
            " 541 542 543 544 545 548 549 551 552 553 554 555 557 558 562 563 565 566\n",
            " 567 568 569 572 573 574 575 576 577 578 579 581 582 583 584 585 587 588\n",
            " 589 590 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 608\n",
            " 610 612 615 616 618 619 621 622 623 625 626 627 628 629 630 631 632 633\n",
            " 634 635 636 637 638 639 640 641 642 643 644 645 646 648 649 650 651 652\n",
            " 653 654 655 657 658 659 660 661 662 663 664 665 666 668 669 671 672 673]\n",
            "test set indices:  [  0   3   6   7  10  12  14  28  31  33  35  38  39  44  45  48  50  51\n",
            "  65  67  77  79  80  81  90  98 100 104 105 114 117 122 124 129 131 134\n",
            " 137 159 163 177 178 196 198 201 203 204 213 219 221 226 235 239 240 241\n",
            " 242 245 253 257 260 263 275 304 306 308 309 315 319 320 333 338 339 344\n",
            " 350 351 353 364 374 381 386 393 394 406 411 416 433 440 441 445 447 455\n",
            " 459 462 468 476 480 482 485 487 497 501 503 505 517 519 520 526 532 534\n",
            " 538 546 547 550 556 559 560 561 564 570 571 580 586 591 607 609 611 613\n",
            " 614 617 620 624 647 656 667 670 674]\n",
            "new_x_train: \n",
            "[[3 False 30.0 1 1 24.15]\n",
            " [2 False 54.0 1 3 23.0]\n",
            " [3 True 28.0 0 0 22.525]\n",
            " ...\n",
            " [1 True 58.0 0 0 29.7]\n",
            " [2 False 24.0 1 0 26.0]\n",
            " [3 False 3.0 1 1 13.775]]\n",
            "new_y_train: \n",
            "[0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0\n",
            " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 1\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0\n",
            " 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1\n",
            " 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0\n",
            " 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0]\n",
            "new_x_test: \n",
            "[[3 True 38.0 0 0 8.6625]\n",
            " [2 True 40.0 0 0 13.0]\n",
            " [2 False 30.0 0 0 13.0]\n",
            " [3 False 22.0 0 0 7.775]\n",
            " [1 False 60.0 0 0 76.2917]\n",
            " [2 False 20.0 2 1 23.0]\n",
            " [3 True 48.0 0 0 7.8542]\n",
            " [3 True 13.0 0 2 20.25]\n",
            " [2 False 29.0 1 0 26.0]\n",
            " [1 False 40.0 1 1 134.5]\n",
            " [1 True 45.0 1 0 83.475]\n",
            " [2 True 57.0 0 0 13.0]\n",
            " [2 False 2.0 1 1 26.0]\n",
            " [2 False 50.0 0 0 10.5]\n",
            " [1 False 14.0 1 2 120.0]\n",
            " [1 True 32.5 0 0 211.5]\n",
            " [1 True 6.0 0 2 134.5]\n",
            " [3 False 37.0 0 0 7.75]\n",
            " [1 False 30.0 0 0 106.425]\n",
            " [3 True 26.0 1 0 14.4542]\n",
            " [1 True 40.0 0 0 0.0]\n",
            " [3 True 47.0 0 0 7.25]\n",
            " [3 True 21.0 0 0 8.05]\n",
            " [2 True 42.0 1 1 32.5]\n",
            " [3 False 22.0 0 0 7.25]\n",
            " [2 False 36.0 1 0 26.0]\n",
            " [1 False 48.0 1 0 106.425]\n",
            " [1 True 36.0 0 0 26.2875]\n",
            " [3 True 11.0 5 2 46.9]\n",
            " [2 True 34.0 0 0 13.0]\n",
            " [2 True 30.0 0 0 10.5]\n",
            " [3 True 21.0 0 0 7.8542]\n",
            " [3 True 45.5 0 0 7.225]\n",
            " [3 True 47.0 0 0 9.0]\n",
            " [1 True 38.0 0 1 153.4625]\n",
            " [3 False 27.0 0 0 7.925]\n",
            " [3 True 26.0 0 0 56.4958]\n",
            " [1 False 24.0 0 0 69.3]\n",
            " [3 True 10.0 4 1 29.125]\n",
            " [1 True 61.0 0 0 33.5]\n",
            " [3 True 16.0 2 0 18.0]\n",
            " [1 False 48.0 1 1 79.2]\n",
            " [2 True 30.0 0 0 12.7375]\n",
            " [1 True 49.0 1 0 56.9292]\n",
            " [1 True 36.0 1 2 120.0]\n",
            " [3 False 1.0 1 1 12.1833]\n",
            " [1 True 30.0 1 0 57.75]\n",
            " [3 True 23.0 0 0 7.8542]\n",
            " [3 False 2.0 0 1 10.4625]\n",
            " [1 False 30.0 0 0 31.0]\n",
            " [1 True 62.0 0 0 26.55]\n",
            " [3 True 30.0 0 0 8.05]\n",
            " [3 True 22.0 0 0 7.25]\n",
            " [1 True 45.5 0 0 28.5]\n",
            " [2 True 30.0 0 0 13.0]\n",
            " [3 False 33.0 3 0 15.85]\n",
            " [3 True 33.0 0 0 9.5]\n",
            " [1 True 25.0 0 0 26.0]\n",
            " [2 True 28.0 0 0 10.5]\n",
            " [3 True 28.0 0 0 9.5]\n",
            " [3 False 24.0 1 0 15.85]\n",
            " [1 False 58.0 0 0 146.5208]\n",
            " [3 True 19.0 0 0 6.75]\n",
            " [3 True 34.0 0 0 8.05]\n",
            " [2 False 14.0 1 0 30.0708]\n",
            " [3 False 18.0 0 0 7.8792]\n",
            " [2 True 40.0 1 0 26.0]\n",
            " [2 True 30.0 1 0 21.0]\n",
            " [3 True 28.0 2 0 7.925]\n",
            " [3 True 14.5 8 2 69.55]\n",
            " [2 True 17.0 0 0 73.5]\n",
            " [2 True 49.0 1 2 65.0]\n",
            " [3 True 55.5 0 0 8.05]\n",
            " [2 True 25.0 1 0 26.0]\n",
            " [3 True 31.0 0 0 7.7333]\n",
            " [1 True 28.0 0 0 35.5]\n",
            " [1 False 18.0 1 0 60.0]\n",
            " [2 True 24.0 0 0 10.5]\n",
            " [1 True 35.0 0 0 26.55]\n",
            " [3 False 22.0 0 0 10.5167]\n",
            " [3 False 35.0 1 1 20.25]\n",
            " [2 True 42.0 0 0 13.0]\n",
            " [2 True 30.0 0 0 13.0]\n",
            " [2 True 22.0 2 0 31.5]\n",
            " [3 True 14.0 5 2 46.9]\n",
            " [1 True 30.0 0 0 45.5]\n",
            " [3 True 21.0 0 0 7.775]\n",
            " [3 True 28.0 0 0 7.25]\n",
            " [3 False 6.0 4 2 31.275]\n",
            " [3 False 4.0 0 1 13.4167]\n",
            " [2 True 24.0 2 0 73.5]\n",
            " [2 False 24.0 1 1 37.0042]\n",
            " [3 False 22.0 0 0 7.75]\n",
            " [2 False 24.0 0 0 13.0]\n",
            " [3 True 14.0 0 0 9.225]\n",
            " [2 True 18.0 0 0 73.5]\n",
            " [3 True 50.0 1 0 14.5]\n",
            " [2 True 3.0 1 1 26.0]\n",
            " [3 True 3.0 4 2 31.3875]\n",
            " [3 True 36.0 1 1 24.15]\n",
            " [1 False 22.0 0 0 151.55]\n",
            " [3 True 28.0 0 0 7.8958]\n",
            " [1 False 44.0 0 1 57.9792]\n",
            " [1 False 36.0 0 0 135.6333]\n",
            " [2 True 8.0 0 2 32.5]\n",
            " [2 True 0.8333 0 2 29.0]\n",
            " [3 True 39.0 1 5 31.275]\n",
            " [2 False 28.0 0 0 13.0]\n",
            " [3 True 24.0 1 0 16.1]\n",
            " [3 True 33.0 0 0 7.8958]\n",
            " [2 True 50.0 0 0 13.0]\n",
            " [3 False 28.0 0 0 7.775]\n",
            " [3 False 30.0 0 0 8.6625]\n",
            " [3 False 31.0 0 0 7.8542]\n",
            " [2 False 29.0 1 0 26.0]\n",
            " [1 False 60.0 1 4 263.0]\n",
            " [3 False 18.0 0 0 7.4958]\n",
            " [3 True 44.0 0 0 7.925]\n",
            " [2 False 22.0 1 2 41.5792]\n",
            " [1 True 29.0 1 0 66.6]\n",
            " [1 False 32.0 0 0 76.2917]\n",
            " [1 False 59.0 2 0 51.4792]\n",
            " [3 True 17.0 0 0 8.6625]\n",
            " [1 False 36.0 0 2 71.0]\n",
            " [1 False 51.0 1 0 77.9583]\n",
            " [2 False 12.0 0 0 15.75]\n",
            " [1 True 55.0 1 1 93.5]\n",
            " [3 False 18.0 0 0 9.8417]\n",
            " [3 False 16.0 5 2 46.9]\n",
            " [1 False 53.0 2 0 51.4792]\n",
            " [2 True 18.0 0 0 73.5]\n",
            " [1 False 54.0 1 0 78.2667]\n",
            " [3 False 16.0 0 0 7.75]\n",
            " [1 True 55.0 0 0 50.0]\n",
            " [2 True 52.0 0 0 13.0]]\n",
            "new_y_test: \n",
            "[0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0]\n",
            "0.8148148148148148\n",
            "[0.8222222222222222, 0.8148148148148148, 0.7777777777777778, 0.7555555555555555, 0.7555555555555555]\n",
            "0.7851851851851851\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "#allows a file to be uploaded to Google Colab directly from the computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#using pandas to create a DataFrame to organize the data\n",
        "df = pd.read_csv(\"titanic_train.csv\")\n",
        "df = df.drop(\"passenger_id\", axis = 'columns')\n",
        "df = df.drop(\"name\", axis = 'columns')\n",
        "df = df.drop(\"ticket\", axis = 'columns')\n",
        "df = df.drop(\"embarked\", axis = 'columns')\n",
        "df = df.drop(\"cabin\", axis = 'columns')\n",
        "df = df.drop(\"boat\", axis = 'columns')\n",
        "df = df.drop(\"body\", axis = 'columns')\n",
        "df = df.drop(\"home.dest\", axis = 'columns')\n",
        "df = df.dropna(subset = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare'])\n",
        "print(df.head)\n",
        "\n",
        "#creates a new column in the DataFrame with boolean values denoting if certain passengers are male or female\n",
        "df['male'] = df['sex'] == 'male'\n",
        "print(df.head)\n",
        "\n",
        "#defining the feature matrix and creating a NumPy array to hold the data of the DataFrame\n",
        "x = df[['pclass', 'male', 'age', 'sibsp', 'parch', 'fare']].values\n",
        "print(x)\n",
        "\n",
        "#defining the target and creating a NumPy array to hold the data of the DataFrame\n",
        "y = df['survived'].values\n",
        "print(y)\n",
        "\n",
        "#importing the Logistic Regression model from Scikit-Learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#creating the logistic regression ML model\n",
        "model = LogisticRegression()\n",
        "model.fit(x,y)\n",
        "\n",
        "#determining the coefficients surrounding the line-of-best-fit\n",
        "print(model.coef_, model.intercept_)\n",
        "\n",
        "#predicting if certain passengers will survive given inputs of class, male/female, age, siblings/spouses, parents/children, and fare\n",
        "print(model.predict([[3, True, 38.0, 0, 0, 8.6625]])) #first passenger\n",
        "\n",
        "#predicting the survivability of the first five passengers and comparing it to the real survivability rates\n",
        "print(model.predict(x[:5]))\n",
        "print(y[:5])\n",
        "\n",
        "#creating an array of predicted y values\n",
        "y_pred = model.predict(x)\n",
        "\n",
        "#comparing to see if each prediction is correct and printing the number of correct predictions\n",
        "y == y_pred\n",
        "print((y == y_pred).sum())\n",
        "\n",
        "#determining the percentage of accuracy employed by the model\n",
        "y.shape[0] #gives the total number of data points in the set\n",
        "print((y == y_pred).sum() / y.shape[0])\n",
        "print(model.score(x, y)) #alternative way of getting the accuracy\n",
        "\n",
        "#calculating the evaluation metrics of the model: accuracy, precision, recall, and f1 score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print(\"accuracy: \", accuracy_score(y, y_pred))\n",
        "print(\"precision: \", precision_score(y, y_pred))\n",
        "print(\"recall: \", recall_score(y, y_pred))\n",
        "print(\"f1 score: \", f1_score(y, y_pred))\n",
        "\n",
        "#outputting the confusion matrix of the model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y, y_pred))\n",
        "\n",
        "#dividing the dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 27) #setting training size to 80% and test size to be 20%\n",
        "print(\"whole dataset: \", x.shape, y.shape)\n",
        "print(\"training set: \", x_train.shape, y_train.shape)\n",
        "print(\"test set: \", x_test.shape, y_test.shape)\n",
        "\n",
        "#re-applying the Logistic Regression model towards the training and test datasets\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "print(model.score(x_test, y_test))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred))\n",
        "print(\"recall: \", recall_score(y_test, y_pred))\n",
        "print(\"f1 score: \", f1_score(y_test, y_pred))\n",
        "\n",
        "#sensitivity score is the same as the recall score\n",
        "from sklearn.metrics import recall_score\n",
        "sensitivity_score = recall_score\n",
        "print(sensitivity_score(y_test, y_pred))\n",
        "\n",
        "#defining a function to output specificity score\n",
        "def specificity_score(y_true, y_pred):\n",
        "  p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
        "  return r[0]\n",
        "\n",
        "#choosing the threshold of the Logistic Regression model to be equal to 0.75\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "print(\"predict proba: \")\n",
        "print(model.predict_proba(x_test))\n",
        "y_pred = model.predict_proba(x_test)[:, 1] > 0.75\n",
        "print(\"precision: \", precision_score(y_test, y_pred))\n",
        "print(\"recall: \", recall_score(y_test, y_pred))\n",
        "\n",
        "#creating a ROC curve comparing specificity against sensitivity\n",
        "from sklearn.metrics import roc_curve\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred_proba = model.predict_proba(x_test)\n",
        "fpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:, 1])\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], linestyle = '--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('1 - specificity')\n",
        "plt.ylabel('sensitivity')\n",
        "plt.show()\n",
        "\n",
        "#calculating the area under the curve for the ROC curve recently plotted\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_test, y_pred_proba[:, 1]))\n",
        "\n",
        "#performing a k-fold cross validation on the data where k = 5\n",
        "from sklearn.model_selection import KFold\n",
        "new_x = df[['pclass', 'male', 'age', 'sibsp', 'parch', 'fare']].values\n",
        "new_y = df['survived'].values\n",
        "\n",
        "kf = KFold(n_splits = 5, shuffle = True)\n",
        "for train, test in kf.split(x):\n",
        "  print(train, test)\n",
        "\n",
        "#setting the first split as training and test sets\n",
        "splits = list(kf.split(new_x))\n",
        "first_split = splits[0]\n",
        "print(first_split)\n",
        "train_indices, test_indices = first_split\n",
        "print(\"training set indices: \", train_indices)\n",
        "print(\"test set indices: \", test_indices)\n",
        "new_x_train = new_x[train_indices]\n",
        "new_x_test = new_x[test_indices]\n",
        "new_y_train = new_y[train_indices]\n",
        "new_y_test = new_y[test_indices]\n",
        "print(\"new_x_train: \")\n",
        "print(new_x_train)\n",
        "print(\"new_y_train: \")\n",
        "print(new_y_train)\n",
        "print(\"new_x_test: \")\n",
        "print(new_x_test)\n",
        "print(\"new_y_test: \")\n",
        "print(new_y_test)\n",
        "\n",
        "#creating and scoring a new Logistic Regression model against the first split\n",
        "new_model = LogisticRegression()\n",
        "new_model.fit(new_x_train, new_y_train)\n",
        "print(new_model.score(new_x_test, new_y_test))\n",
        "\n",
        "#looping over all the folds created\n",
        "scores = []\n",
        "kf = KFold(n_splits = 5, shuffle = True)\n",
        "for train_index, test_index in kf.split(new_x):\n",
        "  new_x_train, new_x_test = new_x[train_index], new_x[test_index] \n",
        "  new_y_train, new_y_test = new_y[train_index], new_y[test_index]\n",
        "  model = LogisticRegression()\n",
        "  model.fit(new_x_train, new_y_train)\n",
        "  scores.append(model.score(new_x_test, new_y_test))\n",
        "print(scores) \n",
        "print(np.mean(scores))\n",
        "\n",
        "#creating a final model utilizing the accuracies of the models created from splits\n",
        "final_model = LogisticRegression()\n",
        "final_model.fit(new_x, new_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wXwWe6hCRQU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}